# BlindVision
## University of Essex - BSc Thesis: Computer Vision and Speech Synthesis Based Scene Understanding for People with Impaired Vision
BlindVision is a mobile application developed for my BSc thesis that leverages Computer Vision and Speech Synthesis to assist individuals with vision impairment. By combining deep learning techniques for object detection and image classification with Optical Character Recognition, the app provides users with an auditory understanding of their surroundings. It features an array of CNN object detection models, including YOLOv4, MobileNetV1 SSD, and EfficientDet Lite series, all trained on the COCO dataset. Google's ML Kit underpins the app's image labeling and text recognition capabilities, while the free Google Vision API extends its textual comprehension. To deliver a seamless user experience, BlindVision incorporates Text-To-Speech for auditory feedback and Speech Recognition for voice commands, enhanced by gesture-based interactions for hands-free use. Through rigorous testing, EfficientDet Lite0 emerged as the top-performing model, achieving an on-device accuracy of 67% and working in tandem with an image classification model with 85% accuracy, delivering real-time performance at 14.4 frames per second. This thesis not only showcases the technical feasibility of BlindVision but also its potential to significantly improve the daily lives of those with vision impairments.


https://github.com/kyriakossk2000/BlindVision/assets/118475289/bb004513-01bd-4488-895e-9fe673894e68

